# 编译链接

## 问题

* 说说include头文件的顺序以及双引号""和尖括号<>的区别
* 简述C++从代码到可执行二进制文件的过程
* 动态链接所有的段都只是一份吗（个人认为是只有代码段是一份的， 因为[数据](https://www.nowcoder.com/jump/super-jump/word?word=数据)的话对于每个进程是私有的，不共享）
* O0、O1、O2、O3 优化
* 什么是 gcc ？工作流程是什么？
* 你知道 Debug 和 Release 的区别是什么吗？
* 谈谈编译优化技巧
* 请你来写个函数在main函数执行前先运行

## 回答

### 说说include头文件的顺序以及双引号""和尖括号<>的区别

（1）尖括号<>的头文件是**系统文件**，双引号""的头文件是**自定义文件**。

（2）编译器预处理阶段查找头文件的路径不一样。

查找路径：

（1）使用尖括号<>的头文件的查找路径：编译器设置的头文件路径-->系统变量。

（2）使用双引号""的头文件的查找路径：当前头文件目录-->编译器设置的头文件路径-->系统变量。

### 简述C++从代码到可执行二进制文件的过程

C++和C语言类似，一个C++程序从源码到执行文件，有四个过程，**预编译、编译、汇编、链接**。

#### **预编译：**

（1） 将所有的#define删除，并且展开所有的宏定义

（2） 处理所有的条件预编译指令，如#if、#ifdef

（3） 处理#include预编译指令，将被包含的文件插入到该预编译指令的位置。

（4） 过滤所有的注释

（5） 添加行号和文件名标识。

#### **编译：**

把预编译之后生成的xxx.i或xxx.ii文件，进行一系列词法分析、语法分析、语义分析及优化后，生成相应 的汇编代码文件。

1. 词法分析：利用类似于“有限状态机”的算法，将源代码程序输入到扫描机中，将其中的字符序列分 割成一系列的记号。
2. 语法分析：语法分析器对由扫描器产生的记号，进行语法分析，产生语法树。由语法分析器输出的 语法树是一种以表达式为节点的树。
3. 语义分析：语法分析器只是完成了对表达式语法层面的分析，语义分析器则对表达式是否有意义进 行判断，其分析的语义是静态语义——在编译期能分期的语义，相对应的动态语义是在运行期才能确定 的语义。
4. 优化：源代码级别的一个优化过程。
5. 目标代码生成：由代码生成器将中间代码转换成目标机器代码，生成一系列的代码序列——汇编语言 表示。
6. 目标代码优化：目标代码优化器对上述的目标机器代码进行优化：寻找合适的寻址方式、使用位移 来替代乘法运算、删除多余的指令等。

#### **汇编：**

这个过程主要是将汇编代码转变成机器可以执行的指令。将汇编代码转变成机器可以执行的指令(机器码文件)。 汇编器的汇编过程相对于编译器来说更简单，没 有复杂的语法，也没有语义，更不需要做指令优化，只是根据汇编指令和机器指令的对照表一一翻译过 来，汇编过程有汇编器as完成。经汇编之后，产生目标文件(与可执行文件格式几乎一样)xxx.o(Windows 下)、xxx.obj(Linux下)。

#### **链接：**（还要细化具体过程）

将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序。

链接分为静态链接和动态链接。

**静态链接**（编译时）

静态链接，是在链接的时候就已经把要调用的函数或者过程链接到了生成的可执行文件中，就算你在去把静态库删除也不会影响可执行程序的执行；生成的静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。

函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库 中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.2/202102/微信截图_20210201114618.png)

静态链接器以一组可重定位目标文件为输入，生成一个完全链接的可执行目标文件作为输出。链接器主要完成以下两个任务：

* 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量，符号解析的目的是将每个符号引用与一个符号定义关联起来。
* 重定位：链接器通过把每个符号定义与一个内存位置关联起来，然后修改所有对这些符号的引用，使得它们指向这个内存位置。

目标文件

* 可执行目标文件：可以直接在内存中执行；
* 可重定位目标文件：可与其它可重定位目标文件在链接阶段合并，创建一个可执行目标文件；
* 共享目标文件：这是一种特殊的可重定位目标文件，可以在运行时被动态加载进内存并链接；

优点

* 运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西， 在执行的时候运行速度快
* 静态编译，编译器在编译可执行文件时，把要用到的对应动态链接库中的部分提取出来，连接到可执行文件中去，使可执行文件在运行时不需要依赖于动态链接库

缺点

* 空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个 目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本（对于 printf 这种标准函数库，如果每个程序都要有代码，这会极大浪费资源。）

* 更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序

**动态链接**（运行时）

动态链接，是在链接的时候没有把调用的函数代码链接进去，而是在执行的过程中，再去找要链接的函数，生成的可执行文件中没有函数代码，只包含函数的重定位信息，所以当你删除动态库时，可执行程序就不能运行。生成的动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。

动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形 成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。

![img](https://cdn.jsdelivr.net/gh/forthespada/mediaImage1@1.6.4.2/202102/微信截图_20210201115700.png)

优点

* 更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运 行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标
* 共享库：执行文件本身的体积。就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副 本，而是这多个程序在执行时共享同一份副本
* 动态编译：加快了编译速度，节省了系统资源

缺点

* 性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损 失
* 哪怕是很简单的程序，只用到了链接库的一两条命令，也需要附带一个相对庞大的链接库
* 如果其他计算机上没有安装对应的运行库，则用动态编译的可执行文件就不能运行

### O0、O1、O2、O3优化

**-O0**

不做任何优化，这是默认的编译选项。

**-O1**

主要对代码的分支、常量以及表达式进行优化。会减小代码的尺寸，缩短执行周期啥的

 -floop-optimize：执行循环优化,将常量表达式从循环中移除，简化判断循环的条件，并且optionally do strength-reduction，或者将循环打开等。在大型复杂的循环中，这种优化比较显著。

**-O2**

O2优化再打开O1优化的前提下，尝试更多的寄存器级的优化以及指令级的优化，它会在编译期间占用更多的内存和编译时间。

所以一般来说可以直接开-O2的优化等级，

**-O3**

 在O2的基础上进行更多的优化，例如使用伪寄存器网络，普通函数的内联，以及针对循环的更多优化。

这个好像不推荐，因为会增加编译失败和程序不可预知的一些行为，不建议使用

### 什么是 gcc ？工作流程是什么？

#### 什么是gcc

**gcc的全称是GNU Compiler Collection，它是一个能够编译多种语言的编译器。**

最开始gcc是作为C语言的编译器（GNU C Compiler），现在除了c语言，还支持C++、java、Pascal等语言。

#### gcc工作流程

* 预处理（--E）
  * 宏替换
  * 头文件展开
  * 去掉注释
  * .c文件变成了.i文件（本质上还是.c文件，只不过#include中的程序给链接进去）
* 编译（--S）
  * gcc调用不同语言的编译器
  * .i文件编程.s（汇编文件）
  * 生成汇编文件

* 汇编（-c）
  * .s文件转化成.o文件
  * 翻译成机器语言指令
  * 二进制文件
* 链接
  * .o文件变成可执行文件，一般不加后缀

> ![img](https://cdn.jsdelivr.net/gh/luogou/cloudimg/data/202201241320667.jpeg)
>
> **预处理**实际上是将头文件、宏进行展开。
>
> **编译阶段**gcc调用不同语言的编译器。gcc实际上是个工具链，在编译程序的过程中调用不同的工具。
>
> **汇编阶段**gcc调用汇编器进行汇编。汇编语言是一种低级语言，在不同的设备中对应着不同的机器语言指令，一种汇编语言专用于某种计算机体系结构，可移植性比较差。通过相应的汇编程序可以将汇编语言转换成可执行的机器代码这一过程叫做汇编过程。汇编器生成的是可重定位的目标文件，在源程序中地址是从0开始的，这是一个相对地址，而程序真正在内存中运行时的地址肯定不是从0开始的，而且在编写源代码的时候也不能知道程序的绝对地址，所以**重定位**能够将源代码的代码、变量等定位为内存具体地址。
>
> **链接过程**会将程序所需要的目标文件进行链接成可执行文件。

#### gcc常用参数

* -v/--version：查看gcc的版本
* -I：编译的时候指定头文件路径，不然头文件找不到
* -c：将汇编文件转换成二进制文件，得到.o文件
* -g：gdb调试的时候需要加
* -D：编译的时候指定一个宏（调试代码的时候需要使用例如printf函数，但是这种函数太多了对程序性能有影响，因此如果没有宏，则#ifdefine的内容不起作用）
* -wall：添加警告信息
* -On：-O是优化代码，n是优化级别：1，2，3

### 你知道 Debug 和 Release 的区别是什么吗？

Debug 版本的存在是为了方便程序员开发和调试，性能和体积不是它的重点；Release 版本是最终交给用户的程序，性能和体积是需要重点优化的两个方面。

在开发过程中，我们一般使用 Debug 版本，只有等到开发完成，确认没有任何 Bug 之后，希望交给用户时再生成 Release 版本。

**Debug 版本**

Debug 是“调试”的意思，Debug 版本就是为调试而生的，编译器在生成 Debug 版本的程序时会加入调试辅助信息，并且很少会进行优化，程序还是“原汁原味”的。

Debug 调试，你在程序中设置了断点，为什么vs.net知道在那里要停下来，当你把鼠标移到某个变量上，vs.net就会显示它当时的值？
因为编译器在代码中添加了许多调试需要的代码，可以让vs.net得到，返回给你。这些代码当然是要占用空间和时间的，在你的程序调试完了后，可以正确运行了。完全可以去掉这些代码，这时候就应该用Release模式了。

**Release 版本**

Release 是“发行”的意思，Release 版本就是最终交给用户的程序，编译器会使尽浑身解数对它进行优化，以提高执行效率，虽然最终的运行结果仍然是我们期望的，但底层的执行流程可能已经改变了。

编译器还会尽量降低 Release 版本的体积，把没用的数据一律剔除，包括调试信息。最终，Release 版本是一个小巧精悍、非常纯粹、为用户而生的程序。Release代码更小,执行更快,编译更严格,更慢

### 谈谈编译优化技巧

美团技术团队：[C++服务编译耗时优化原理及实践](https://tech.meituan.com/2020/12/10/apache-kylin-practice-in-meituan.html)

#### 二、编译原理及分析

##### 2.1 编译原理介绍

为了更好地理解编译优化方案，在介绍优化方案之前，我们先简单介绍一下编译原理，通常我们在进行C++开发时，编译的过程主要包含下面四个步骤：

![img](https://p0.meituan.net/travelcube/d152ab606e08516d8369211b19da87fc29998.png@912w_155h_80q)

**预处理器**：宏定义替换，头文件展开，条件编译展开，删除注释。

* gcc -E选项可以得到预处理后的结果，扩展名为.i 或 .ii。
* C/C++预处理不做任何语法检查，不仅是因为它不具备语法检查功能，也因为预处理命令不属于C/C++语句（这也是定义宏时不要加分号的原因），语法检查是编译器要做的事情。
* 预处理之后，得到的仅仅是真正的源代码。

**编译器**：生成汇编代码，得到汇编语言程序（把高级语言翻译为机器语言），该种语言程序中的每条语句都以一种标准的文本格式确切的描述了一条低级机器语言指令。

* gcc -S选项可以得到编译后的汇编代码文件，扩展名为.s。
* 汇编语言为不同高级语言的不同编译器提供了通用的输出语言。

**汇编器**：生成目标文件。

* gcc -c选项可以得到汇编后的结果文件，扩展名为.o。
* .o文件，是按照的二进制编码方式生成的文件。

**链接器**：生成可执行文件或库文件。

* **静态库**：指编译链接时，把库文件的代码全部加入到可执行文件中，因此生成的文件比较大，但在运行时也就不再需要库文件了，其后缀名一般为“.a”。
* **动态库**：在编译链接时并没有把库文件的代码加入到可执行文件中，而是在程序执行时由运行时链接文件加载库，这样可执行文件比较小，动态库一般后缀名为“.so”。
* **可执行文件**：将所有的二进制文件链接起来融合成一个可执行程序，不管这些文件是目标二进制文件还是库二进制文件。

#### 2.2 C++编译特点

（1）每个源文件独立编译

C/C++的编译系统和其他高级语言存在很大的差异，其他高级语言中，编译单元是整个Module，即Module下所有源码，会在同一个编译任务中执行。而在C/C++中，编译单元是以文件为单位。每个.c/.cc/.cxx/.cpp源文件是一个独立的编译单元，导致编译优化时只能基于本文件内容进行优化，很难跨编译单元提供代码优化。

（2）每个编译单元，都需要独立解析所有包含的头文件

如果N个源文件引用到了同一个头文件，则这个头文件需要解析N次（对于Thrift文件或者Boost头文件这类动辄几千上万行的头文件来说，简直就是“鬼故事”）。

如果头文件中有模板（STL/Boost），则该模板在每个cpp文件中使用时都会做一次实例化，N个源文件中的std::vector会实例化N次。

（3）模板函数实例化

在C++ 98语言标准中，对于源代码中出现的每一处模板实例化，编译器都需要去做实例化的工作；而在链接时，链接器还需要移除重复的实例化代码。显然编译器遇到一个模板定义时，每次都去进行重复的实例化工作，进行重复的编译工作。此时，如果能够让编译器避免此类重复的实例化工作，那么可以大大提高编译器的工作效率。在C++ 0x标准中一个新的语言特性 – 外部模板的引入解决了这个问题。

在C++ 98中，已经有一个叫做显式实例化（Explicit Instantiation）的语言特性，它的目的是指示编译器立即进行模板实例化操作（即强制实例化）。而外部模板语法就是在显式实例化指令的语法基础上进行修改得到的，通过在显式实例化指令前添加前缀extern，从而得到外部模板的语法。

① 显式实例化语法：template class vector。 ② 外部模板语法：extern template class vector。

一旦在一个编译单元中使用了外部模板声明，那么编译器在编译该编译单元时，会跳过与该外部模板声明匹配的模板实例化。

（4）虚函数

编译器处理虚函数的方法是：给每个对象添加一个指针，存放了指向虚函数表的地址，虚函数表存储了该类（包括继承自基类）的虚函数地址。如果派生类重写了虚函数的新定义，该虚函数表将保存新函数的地址，如果派生类没有重新定义虚函数，该虚函数表将保存函数原始版本的地址。如果派生类定义了新的虚函数，则该函数的地址将被添加到虚函数表中。

调用虚函数时，程序将查看存储在对象中的虚函数表地址，转向相应的虚函数表，使用类声明中定义的第几个虚函数，程序就使用数组的第几个函数地址，并执行该函数。

使用虚函数后的变化：

① 对象将增加一个存储地址的空间（32位系统为4字节，64位为8字节）。 ② 每个类编译器都创建一个虚函数地址表。 ③ 对每个函数调用都需要增加在表中查找地址的操作。

（5）编译优化

GCC提供了为了满足用户不同程度的的优化需要，提供了近百种优化选项，用来对编译时间，目标文件长度，执行效率这个三维模型进行不同的取舍和平衡。优化的方法不一而足，总体上将有以下几类：

① 精简操作指令。 ② 尽量满足CPU的流水操作。 ③ 通过对程序行为地猜测，重新调整代码的执行顺序。 ④ 充分使用寄存器。 ⑤ 对简单的调用进行展开等等。

如果全部了解这些编译选项，对代码针对性的优化还是一项复杂的工作，幸运的是GCC提供了从O0-O3以及Os这几种不同的优化级别供大家选择，在这些选项中，包含了大部分有效的编译优化选项，并且可以在这个基础上，对某些选项进行屏蔽或添加，从而大大降低了使用的难度。

* O0：不做任何优化，这是默认的编译选项。
* O和O1：对程序做部分编译优化，编译器会尝试减小生成代码的尺寸，以及缩短执行时间，但并不执行需要占用大量编译时间的优化。
* O2：是比O1更高级的选项，进行更多的优化。GCC将执行几乎所有的不包含时间和空间折中的优化。当设置O2选项时，编译器并不进行循环展开以及函数内联优化。与O1比较而言，O2优化增加了编译时间的基础上，提高了生成代码的执行效率。
* O3：在O2的基础上进行更多的优化，例如使用伪寄存器网络，普通函数的内联，以及针对循环的更多优化。
* Os：主要是对代码大小的优化， 通常各种优化都会打乱程序的结构，让调试工作变得无从着手。并且会打乱执行顺序，依赖内存操作顺序的程序需要做相关处理才能确保程序的正确性。

编译优化有可能带来的问题：

① **调试问题**：正如上面所提到的，任何级别的优化都将带来代码结构的改变。例如：对分支的合并和消除，对公用子表达式的消除，对循环内load/store操作的替换和更改等，都将会使目标代码的执行顺序变得面目全非，导致调试信息严重不足。

② **内存操作顺序改变问题**：在O2优化后，编译器会对影响内存操作的执行顺序。例如：-fschedule-insns允许数据处理时先完成其他的指令；-fforce-mem有可能导致内存与寄存器之间的数据产生类似脏数据的不一致等。对于某些依赖内存操作顺序而进行的逻辑，需要做严格的处理后才能进行优化。例如，采用Volatile关键字限制变量的操作方式，或者利用Barrier迫使CPU严格按照指令序执行。

(6)C/C++ 跨编译单元的优化只能交给链接器

当链接器进行链接的时候，首先决定各个目标文件在最终可执行文件里的位置。然后访问所有目标文件的地址重定义表，对其中记录的地址进行重定向（加上一个偏移量，即该编译单元在可执行文件上的起始地址）。然后遍历所有目标文件的未解决符号表，并且在所有的导出符号表里查找匹配的符号，并在未解决符号表中所记录的位置上填写实现地址，最后把所有的目标文件的内容写在各自的位置上，就生成一个可执行文件。链接的细节比较复杂，链接阶段是单进程，无法并行加速，导致大项目链接极慢。

#### 三、服务问题分析

DQU是美团搜索使用的查询理解平台，内部包含了大量的模型、词表、在代码结构上，包含20多个Thrift文件 ，使用大量Boost处理函数 ，同时引入了SF框架，公司第三方组件SDK以及分词三个Submodule，各个模块采用动态库编译加载的方式，模块之间通过消息总线做数据的传输，消息总线是一个大的Event类，这样这个类就包含了各个模块需要的数据类型的定义，所以各个模块都会引入Event头文件，不合理的依赖关系造成这个文件被改动，几乎所有的模块都会重新编译。

![img](https://p0.meituan.net/travelcube/b24a93a4957fe95948f2f953176507c653198.png@583w_458h_80q)

每个服务所面临的编译问题都有各自的特点，但是遇到问题的本质原因是类似的，结合编译的过程和原理，我们从预编译展开、头文件依赖以及编译过程耗时3个方面对DQU服务编译问题进行了分析。

##### 3.1 编译展开分析

编译展开分析就是通过C++的预编译阶段保留的.ii文件，查看通过展开后的编译文件大小，具体可以通过在cmake中指定编译选型 “-save-temps” 保留编译中间文件。

```
set(CMAKE_CXX_FLAGS "-std=c++11 ${CMAKE_CXX_FLAGS} -ggdb -Og -fPIC -w -Wl,--export-dynamic -Wno-deprecated -fpermissive -save-temps")
```

编译耗时的最直接原因就是编译文件展开之后比较大，通过编译展开后的文件大小和内容，通过预编译展开分析能看到文件展开后的文件有40多万行，发现有大量的Boost库引用及头文件引用造成的展开文件比较大，影响到编译的耗时。通过这个方式能够找到各个文件编译耗时的共性，下图是编译展开后文件大小截图。

![img](https://p1.meituan.net/travelcube/e21c707d691f37ae1aa0f674da634d52488160.png@1920w_288h_80q)

##### 3.2 头文件依赖分析

头文件依赖分析是从引用头文件数量的角度来看代码是否合理的一种分析方式，我们实现了一个脚本，用来统计头文件的依赖关系，并且分析输出头文件依赖引用计数，用来辅助判断头文件依赖关系是否合理。

(1) 头文件引用总数结果统计

通过工具统计出编译源文件直接和间接依赖的头文件的总个数，用来从头文件引入数量上分析问题。

![img](https://p0.meituan.net/travelcube/e0603312a066a86cc2546ee717eda99774462.png@998w_368h_80q)

(2) 单个头文件依赖关系统计

通过工具分析头文件依赖关系，生成依赖关系拓扑图，能够直观的看到依赖不合理的地方。

图中包含引用层次关系，以及引用头文件个数。

![img](https://p0.meituan.net/travelcube/67d830a520b8c50ec4ef0657fcfdb93134786.png@450w_467h_80q)

##### 3.3 编译耗时结果分段统计

编译耗时分段统计是从结果上看各个文件的编译耗时以及各个编译阶段的耗时情况，这个是直观的一个结果，正常情况下，是和文件展开大小以及头文件引用个数是正相关的，cmake通过指定环境变量能打印出编译和链接阶段的耗时情况，通过这个数据能直观的分析出耗时情况。

```
set_property(GLOBAL PROPERTY RULE_LAUNCH_COMPILE "${CMAKE_COMMAND} -E time")
set_property(GLOBAL PROPERTY RULE_LAUNCH_LINK "${CMAKE_COMMAND} -E time")
```

**编译耗时结果输出：**

![img](https://p1.meituan.net/travelcube/925cede8222e51701173be3820f37a0d643669.png@1736w_492h_80q)

##### 3.4 分析工具建设

通过上面的工具分析能拿到几个编译数据：

① 头文件依赖关系及个数。 ② 预编译展开大小及内容。 ③ 各个文件编译耗时。 ④ 整体链接耗时。 ⑤ 可以计算出编译并行度。

通过这几个数据的输入我们考虑可以做个自动化分析工具，找出优化点以及界面化展示。基于这个目的，我们建设了全流程自动化分析工具，能够自动分析耗时共性问题以及TopN耗时文件。分析工具处理流程如下图所示：

![img](https://p0.meituan.net/travelcube/3653934c49f0043d91f0268e8b2d8d3243365.png@778w_370h_80q)

(1) 整体统计分析效果

![img](https://p0.meituan.net/travelcube/f21cd0180864beed2def8f3a3f74b1c5593737.png@1920w_534h_80q)

具体字段说明：

① cost_time 编译耗时，单位是秒。 ② file_compile_size，编译中间文件大小，单位是M。 ③ file_name，文件名称。 ④ include_h_nums，引入头文件个数，单位是个。 ⑤ top_h_files_info， 引入最多的TopN头文件。

(2）Top10 编译耗时文件统计

用来展示统计编译耗时最久的TopN文件，N可以自定义指定。

![img](https://p0.meituan.net/travelcube/903ae62dde24d57fbcb1cc692f70039a423114.png@1920w_2297h_80q)

（3）Top10编译中间文件大小统计

通过统计和展示编译文件大小，用来判断这块是否符合预期，这个是和编译耗时一一对应的。

![img](https://p1.meituan.net/travelcube/305e022a376aebf7ae41cdaf0e83e57d469162.png@1920w_2297h_80q)

（4）Top10引入最多头文件的头文件统计

![img](https://p0.meituan.net/travelcube/a4ec2fa1404610ec0c209979ded4cf43468870.png@1920w_2222h_80q)

（5）Top10头文件重复次数统计

![img](https://p0.meituan.net/travelcube/69e4227b89672eb2b31a822dcb29878f542015.png@1920w_2175h_80q)

目前，这个工具支持一键化生成编译耗时分析结果，其中几个小工具，比如依赖文件个数工具已经集成到公司的上线集成测试流程中，通过自动化工具检查代码改动对编译耗时的影响，工具的建设还在不断迭代优化中，后续会集成到公司的MCD平台中，可以自动分析来定位编译耗时长的问题，解决其它部门编译耗时问题。

#### 四、优化方案与实践

通过运用上述相关工具，我们能够发现Top10编译耗时文件的共性，比如都依赖消息总线文件platform_query_analysis_enent.h，这个文件又直接间接引入2000多个头文件，我们重点优化了这类文件，通过工具的编译展开，找出了Boost使用、模板类展开、Thrift头文件展开等共性问题，并针对这些问题做专门的优化。此外，我们也使用了一些业内通用的编译优化方案，并取得了不错的效果。下面详细介绍我们采用的各种优化方案。

##### 4.1 通用编译加速方案

业内有不少通用编译加速工具（方案），无需侵入代码就能提高编译速度，非常值得尝试。

（1）并行编译

在Linux平台上一般使用GNU的Make工具进行编译，在执行make命令时可以加上`-j`参数增加编译并行度，如`make -j 4`将开启4个任务。在实践中我们并不将该参数写死，而是通过`$(nproc)`方法动态获取编译机的CPU核数作为编译并发度，从而最大限度利用多核的性能优势。

（2）分布式编译

使用分布式编译技术，比如利用Distcc和Dmucs构建大规模、分布式C++编译环境，Linux平台利用网络集群进行分布式编译，需要考虑网络时延与网络稳定性。分布式编译适合规模较大的项目，比如单机编译需要数小时甚至数天。DQU服务从代码规模以及单机编译时长来说，暂时还不需要使用分布式的方式来加速，具体细节可以参考Distcc官方文档说明。

（3）预编译头文件

PCH（[Precompiled Header](<https://en.wikipedia.org/wiki/Precompiled_header#:~:text=In> computer programming%2C a precompiled,to process for the compiler)），该方法预先将常用头文件的编译结果保存起来，这样编译器在处理对应的头文件引入时可以直接使用预先编译好的结果，从而加快整个编译流程。PCH是业内十分常用的加速编译的方法，且大家反馈效果非常不错。在我们的项目中，由于涉及到很多Shared Library的编译生成，而Shared Library相互之间无法共享PCH，因此没有取得预想效果。

（4）CCache

CCache（[Compiler Cache](https://ccache.dev/）)是一个编译缓存工具，其原理是将cpp的编译结果保存在文件缓存中，以后编译时若对应文件无变动可直接从缓存中获取编译结果。需要注意的是，Make本身也有一定缓存功能，当目标文件已编译（且依赖无变化）时，若源文件时间戳无变化也不会再次编译；但CCache是按文件内容做的缓存，且同一机器的多个项目可以共享缓存，因此适用面更大。

（5）Module编译

如果你的项目是用C++ 20进行开发的，那么恭喜你，Module编译也是一个优化编译速度的方案，C++20之前的版本会把每一个cpp当做一个编译单元处理，会存在引入的头文件被多次解析编译的问题。而Module的出现就是解决这一问题，Module不再需要头文件（只需要一个模块文件，不需要声明和实现两个文件），它会将你的（.ixx 或者 .cppm）模块实体直接编译，并自动生成一个二进制接口文件。import和include预处理不同，编译好的模块下次import的时候不会重复编译，可以大幅度提高编译器的效率。

（6）自动依赖分析

Google也推出了开源的Include-What-You-Use工具（简称IWYU），基于Clang的C/C++工程冗余头文件检查工具。IWYU依赖Clang编译套件，使用该工具可以扫描出文件依赖问题，同时该工具还提供脚本解决头文件依赖问题，我们尝试搭建了这套分析工具，这个工具也提供自动化头文件解决方案，但是由于我们的代码依赖比较复杂，有动态库、静态库、子仓库等，这个工具提供的优化功能不能直接使用，其它团队如果代码结构比较简单的话，可以考虑使用这个工具分析优化，会生成如下结果文件，指导哪些头文件需要删除。

```
>>> Fixing #includes in '/opt/meituan/zhoulei/query_analysis/src/common/qa/record/brand_record.h'
@@ -1,9 +1,10 @@

 #ifndef _MTINTENTION_DATA_BRAND_RECORD_H_
 #define _MTINTENTION_DATA_BRAND_RECORD_H_
-#include "qa/data/record.h"
-#include "qa/data/template_map.hpp"
-#include "qa/data/template_vector.hpp"
-#include <boost/serialization/version.hpp>
+#include <boost/serialization/version.hpp>  // for BOOST_CLASS_VERSION
+#include <string>                       // for string
+#include <vector>                       // for vector
+
+#include "qa/data/file_buffer.h"        // for REG_TEMPLATE_FILE_HANDLER

```

##### 4.2 代码优化方案与实践

（1）前置类型声明

通过分析头文件引用统计，我们发现项目中被引用最多的是总线类型Event，而该类型中又放置了各种业务需要的成员，示例如下：

```
#include “a.h”
#include "b.h"
class Event {
// 业务A, B, C ...
  A1 a1;
  A2 a2;
  // ...
  B1 b1;
  B2 b2;
  // ...
};
```

这导致Event中包含了数量庞大的头文件，在头文件展开后，文件大小达到15M；而各种业务都会需要使用Event，自然会严重拖累编译性能。

我们通过前置类型声明来解决这个问题，即不引入对应类型的头文件，只做前置声明，在Event中只使用对应类型的指针，如下所示：

```class
class A2;
// ...
class Event {
// 业务A, B, C ...
  shared_ptr<A1> a1;
  shared_ptr<A2> a2;
  // ...
  shared_ptr<B1> b1;
  shared_ptr<B2> b2;
  // ...
};
```

只有在真正使用对应成员变量时，才需要引入对应头文件；这样真正做到了按需引入头文件。

（2）外部模板

由于模板被使用时才会实例化这一特性，相同的实例可以出现在多个文件对象中。编译器要对每一处模板进行实例化，链接器还要移除重复的实例化代码。当在广泛使用模板的项目中，编译器会产生大量的冗余代码，这会极大地增加编译时间和链接时间。C++ 11新标准中可以通过外部模板来避免。

```C++
// util.h
template <typename T> 
void max(T) { ... }
// A.cpp
extern template void max<int>(int);
#include "util.h"
template void max<int>(int); // 显式地实例化 
void test1()
{ 
    max(1);
}
```

在编译A.cpp的时候，实例化出一个 max(int)版本的函数。

```C++
// B.cpp
#include "util.h"
extern template void max<int>(int); // 外部模板的声明
void test2()
{
    max(2);
}
```

在编译B.cpp的时候，就不再生成 max(int)实例化代码，这样就节省了前面提到的实例化，编译以及链接的耗时了。

（3）多态替换模板使用

我们的项目重度使用词典相关操作，如加载词典、解析词典、匹配词典（各种花式匹配），这些操作都是通过Template模板扩展支持各种不同类型的词典。据统计，词典的类型超过150个，这也造成模板展开的代码量膨胀。

```C++
template <class R>
class Dict {
public:
  // 匹配key和condition，赋值给record
  bool match(const string &key, const string &condition, R &record);  // 对每种类型的Record都会展开一次
private:
  map<string, R> dict;
};
```

幸运的是，我们词典的绝大部分操作都可以抽象出几类接口，因此可以只实现针对基类的操作：

```C++
class Record {  // 基类
public:
  virtual bool match(const string &condition);  // 派生类需实现
};

class Dict {
public:
  shared_ptr<Record> match(const string &key, const string &condition);  // 使用方传入派生类的指针即可
private:
  map<string, shared_ptr<Record>> dict;
};
```

通过继承和多态，我们有效避免了大量的模板展开。需要注意的是，使用指针作为Map的Value会增加内存分配的压力，推荐使用Tcmalloc或Jemalloc替换默认的Ptmalloc优化内存分配。

（4）替换Boost库

Boost是一个广泛使用的基础库，涵盖了大量常用函数，十分方便、好用，然而也存在一些不足之处。一个显著缺点是其实现采用了hpp的形式，即声明和实现均放在头文件中，这会造成预编译展开后十分巨大。

```C++
// 字符串操作是常用功能，仅仅引入该头文件展开大小就超过4M
#include <boost/algorithm/string.hpp>
// 与此相对的，引入多个STL的头文件，展开后仅仅只有1M
#include <vector>
#include <map>
// ...
```

在我们项目中主要使用的Boost函数不超过二十个，部分可以在STL中找到替代，部分我们手动做了实现，使得项目从重度依赖Boost转变成绝大部分达到Boost-Free，大大降低了编译的负担。

（5）预编译

代码中有一些平常改动比较少，但是对编译耗时产生一定的影响，比如Thrift生成的文件，模型库文件以及Common目录下的通用文件，我们采取提起预编译成动态库，减少后续文件的编译耗时，也解决了部分编译依赖。

（6）解决编译依赖，提高编译并行度

在我们项目中有大量模块级别的动态库文件需要编译，cmake文件指定的编译依赖关系在一定程度上限制了编译并行度的执行。

比如下面这个场景，通过合理设置库文件依赖关系，可以提高编译并行度。

![img](https://p0.meituan.net/travelcube/8fe9366374b9560f459457a727f8202f84890.png@1604w_561h_80q)

##### 4.3 优化效果

我们通过32C、64G内存机器做了编译耗时优化前后的效果对比，统计结果如下：

![img](https://p0.meituan.net/travelcube/be9bc08e5cd6164bf06a320ddd42891a440783.png@1420w_870h_80q)

##### 4.4 守住优化成果

编译优化是一件“逆水行舟”的事情，开发人员总是倾向于不断增加新的功能、新的库乃至新的框架，而要删除旧代码、旧库、下线旧框架总是困难重重（相信一线开发人员一定深有体会）。因此，如何守住之前取得的优化成果也是至关重要的。我们在实践中有以下几点体会：

* 代码审核是困难的（引起编译耗时增加的改动，往往无法通过审核代码直观地发现）。
* 工具、流程才值得依赖。
* 关键在于控制增量。

我们发现，cpp文件的编译耗时，和其预编译展开文件（.ii）大小呈正相关（绝大部分情况下）；对每一个上线版本，将其所有cpp文件的预编译展开大小记录下来，就形成了其编译指纹（CF，Compile Fingerprint）。通过比较相邻两个版本的CF，就能较准确的知道新版带来的编译耗时主要由哪些改动引入，并可以进一步分析耗时上涨是否合理，是否有优化空间。

我们将该种方式制作成脚本工具并引入上线流程，从而能够很清楚的了解每次代码发版带来的编译性能影响，并有效地帮助我们守住前期的优化成果。

### 请你来写个函数在main函数执行前先运行

方法一：全局变量的构造函数，会在main之前执行。

```c++
#include <iostream>
using namespace std;

class app
{
public:
    //构造函数
    app()
    {
        cout<<"First"<<endl;
    }
};

app a;  // 申明一个全局变量

int main()
{
    cout<<"Second"<<endl;
    return 0;
}
```

方法二：全局变量的赋值函数，会在main之前执行。（C中好像不允许通过函数给全局变量赋值）

```c++
#include <iostream>
using namespace std;

int f(){
    printf("before");
    return 0;
}

int _ = f();

int main(){
    return 0;
}
```

方法三：如果是**GNUC**的编译器（gcc，clang），就在你要执行的方法前加上 `__attribute__((constructor))`

```c++
#include<stdio.h>

__attribute__((constructor)) void func()
{
    printf("hello world\n");
}

int main()
{
    printf("main\n"); //从运行结果来看，并没有执行main函数
}
```

同理，如果想要在main函数结束之后运行，可加上\__sttribute__((destructor)).

```c++
#include<stdio.h>

void func()
{
    printf("hello world\n");
    //exit(0);
    return 0;
}

__attribute((constructor))void before()
{
    printf("before\n");
    func();
}


__attribute((destructor))void after()
{
    printf("after\n");

}

int main()
{
    printf("main\n"); //从运行结果来看，并没有执行main函数
}
```
